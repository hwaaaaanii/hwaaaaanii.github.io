---
layout: page
icon: fas fa-solid fa-laptop-code
order: 3
---

# **Research and Projects**

**This page shares and details the codes and their contents from the projects and research activities I have conducted. Most of these projects and research are in areas such as natural language processing (NLP), retrieval-augmented generation (RAG) systems, machine learning, and deep learning. You can check out the detailed content and code for each project through the links below.**

## **List of Researches**

**International Publications**
- [ACL 2025] [Word2Passage: Word-level Importance Re-weighting for Query Expansion](https://aclanthology.org/2025.findings-acl.434/)
Jeonghwan Choi, Minjeong Ban, Minseok Kim, Hwanjun Song
Findings of the Association for Computational Linguistics (Findings of ACL), 2025.

- [ArXiv] [Ext2Gen: Alignment through Unified Extraction and Generation for Robust Retrieval-Augmented Generation](https://arxiv.org/abs/2503.04789)
Hwanjun Song, Jeonghwan Choi, Minseok Kim
ArXiv Preprint, 2025.

- [COLING] [Learning to Verify Summary Facts with Fine-Grained LLM Feedback](https://aclanthology.org/2025.coling-main.16/)
Jihwan Oh, Jeonghwan Choi, Nicole Hee-Yeon Kim, Taewon Yun, Hwanjun Song
International Conference on Computational Linguistics (COLING), 2025.

**International Publications**
- [KCC 2025] A Benchmark Dataset for Retrieval-Augmented Generation Considering Performance Alignment between Retrieval and Generation
Minjeong Ban, Jeonghwan Choi, Hyangsuk Min, Taewon Yun, Jihwan Oh, Hwanjun Song
Korea Computer Congress (KCC), 2025.

- [KCC 2025] Robust Dataset Condensation via Semi-Supervised Learning
Hee-yeon Kim, Jeonghwan Choi, Yuho Lee, Hwanjun Song
Korea Computer Congress (KCC), 2025.

- [KIISE 2025] Improving Language Model Quality through LLM-based Fine-Grained Hallucinated Summary Generation
Jihwan Oh, Jeonghwan Choi, Nicole Hee-Yeon Kim, Taewon Yun, Hwanjun Song
KIISE Transactions on Computing Practices, 2025.

- [KCC 2024] [Improving the Text Summary Quality Through Understanding the Hallucination Level of Summarization Using Large Language Models(LLM을 활용한 요약의 환각 수준 이해를 통한 텍스트 요약 품질 향상)](https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE11861883)
  - Awarded for Outstanding Paper Presentation

## **List of Projects**

- [Project] [Data Driven Decision Optimization](https://github.com/hwaaaaanii/Data-Driven-Decision-Optimization-Using-Bayesian-Optimization/tree/main)

  This project is a study that uses Bayesian Optimization to integrate and evaluate various machine learning models for data-driven decision optimization. It thoroughly covers performance evaluation, model selection, hyperparameter optimization, and presents an approach to prediction and optimization based on actual data.
